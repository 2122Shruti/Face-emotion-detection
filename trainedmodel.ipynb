{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "b2418ef9",
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.utils import to_categorical\n",
    "from keras.preprocessing.image import load_img\n",
    "from keras.models import Sequential \n",
    "from keras.layers import Dense, Conv2D, Dropout, Flatten, MaxPooling2D\n",
    "import os\n",
    "import pandas as pd \n",
    "import numpy as np\n",
    "from IPython.display import display\n",
    "from keras.utils import to_categorical\n",
    "from keras.preprocessing.image import load_img\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "0bbb3641",
   "metadata": {},
   "outputs": [],
   "source": [
    "TRAIN_DIR = 'images/train'\n",
    "TEST_DIR = 'images/test'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "427d600b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def createdataframe(dir):\n",
    "    image_paths = []\n",
    "    labels = []\n",
    "    for label in os.listdir(dir):\n",
    "        for imagename in os.listdir(os.path.join(dir,label)):\n",
    "            image_paths.append(os.path.join(dir,label,imagename))\n",
    "            labels.append(label)\n",
    "        print(label, \"completed\")\n",
    "    return image_paths,labels    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "b1a16f0b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "angry completed\n",
      "disgust completed\n",
      "fear completed\n",
      "happy completed\n",
      "neutral completed\n",
      "sad completed\n",
      "surprise completed\n"
     ]
    }
   ],
   "source": [
    "train = pd.DataFrame()\n",
    "train['image'], train['label'] = createdataframe(TRAIN_DIR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "83da2eec",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                image     label\n",
      "0            images/train\\angry\\0.jpg     angry\n",
      "1            images/train\\angry\\1.jpg     angry\n",
      "2           images/train\\angry\\10.jpg     angry\n",
      "3        images/train\\angry\\10002.jpg     angry\n",
      "4        images/train\\angry\\10016.jpg     angry\n",
      "...                               ...       ...\n",
      "28816  images/train\\surprise\\9969.jpg  surprise\n",
      "28817  images/train\\surprise\\9985.jpg  surprise\n",
      "28818  images/train\\surprise\\9990.jpg  surprise\n",
      "28819  images/train\\surprise\\9992.jpg  surprise\n",
      "28820  images/train\\surprise\\9996.jpg  surprise\n",
      "\n",
      "[28821 rows x 2 columns]\n"
     ]
    }
   ],
   "source": [
    "print(train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "6c29a350",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "angry completed\n",
      "disgust completed\n",
      "fear completed\n",
      "happy completed\n",
      "neutral completed\n",
      "sad completed\n",
      "surprise completed\n"
     ]
    }
   ],
   "source": [
    "test = pd.DataFrame()\n",
    "test['image'], test['label'] = createdataframe(TEST_DIR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "3ead16a3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                              image     label\n",
      "0       images/test\\angry\\10052.jpg     angry\n",
      "1       images/test\\angry\\10065.jpg     angry\n",
      "2       images/test\\angry\\10079.jpg     angry\n",
      "3       images/test\\angry\\10095.jpg     angry\n",
      "4       images/test\\angry\\10121.jpg     angry\n",
      "...                             ...       ...\n",
      "7061  images/test\\surprise\\9806.jpg  surprise\n",
      "7062  images/test\\surprise\\9830.jpg  surprise\n",
      "7063  images/test\\surprise\\9853.jpg  surprise\n",
      "7064  images/test\\surprise\\9878.jpg  surprise\n",
      "7065   images/test\\surprise\\993.jpg  surprise\n",
      "\n",
      "[7066 rows x 2 columns]\n",
      "0         images/test\\angry\\10052.jpg\n",
      "1         images/test\\angry\\10065.jpg\n",
      "2         images/test\\angry\\10079.jpg\n",
      "3         images/test\\angry\\10095.jpg\n",
      "4         images/test\\angry\\10121.jpg\n",
      "                    ...              \n",
      "7061    images/test\\surprise\\9806.jpg\n",
      "7062    images/test\\surprise\\9830.jpg\n",
      "7063    images/test\\surprise\\9853.jpg\n",
      "7064    images/test\\surprise\\9878.jpg\n",
      "7065     images/test\\surprise\\993.jpg\n",
      "Name: image, Length: 7066, dtype: object\n"
     ]
    }
   ],
   "source": [
    "print(test)\n",
    "print(test['image'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "d47cd218",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0              images/train\\angry\\0.jpg\n",
      "1              images/train\\angry\\1.jpg\n",
      "2             images/train\\angry\\10.jpg\n",
      "3          images/train\\angry\\10002.jpg\n",
      "4          images/train\\angry\\10016.jpg\n",
      "                      ...              \n",
      "28816    images/train\\surprise\\9969.jpg\n",
      "28817    images/train\\surprise\\9985.jpg\n",
      "28818    images/train\\surprise\\9990.jpg\n",
      "28819    images/train\\surprise\\9992.jpg\n",
      "28820    images/train\\surprise\\9996.jpg\n",
      "Name: image, Length: 28821, dtype: object\n"
     ]
    }
   ],
   "source": [
    "print(train['image'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "db84be09",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm.notebook import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "af9a7e58",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_features(images):\n",
    "    features = []\n",
    "    for image in tqdm(images):\n",
    "        img = load_img(image,color_mode = \"grayscale\" )\n",
    "        img = np.array(img)\n",
    "        features.append(img)\n",
    "    features = np.array(features)\n",
    "    features = features.reshape(len(features),48,48,1)\n",
    "    return features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "6bc275e5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f7868b4974664774842436184276b9cb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/28821 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "train_features = extract_features(train['image'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "23e950e4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f2d3aafb8d774c2c8282efd59139756d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/7066 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "test_features = extract_features(test['image'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "caf4fc58",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train = train_features/255.0\n",
    "x_test = test_features/255.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "8b89cca8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import LabelEncoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "dc8a2cf2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-1 {color: black;}#sk-container-id-1 pre{padding: 0;}#sk-container-id-1 div.sk-toggleable {background-color: white;}#sk-container-id-1 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-1 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-1 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-1 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-1 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-1 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-1 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-1 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-1 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-1 div.sk-item {position: relative;z-index: 1;}#sk-container-id-1 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-1 div.sk-item::before, #sk-container-id-1 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-1 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-1 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-1 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-1 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-1 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-1 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-1 div.sk-label-container {text-align: center;}#sk-container-id-1 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-1 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>LabelEncoder()</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" checked><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">LabelEncoder</label><div class=\"sk-toggleable__content\"><pre>LabelEncoder()</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "LabelEncoder()"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "le = LabelEncoder()\n",
    "le.fit(train['label'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "110282ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train = le.transform(train['label'])\n",
    "y_test = le.transform(test['label'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "9e89b85a",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train = to_categorical(y_train,num_classes = 7)\n",
    "y_test = to_categorical(y_test,num_classes = 7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "feff035d",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "# convolutional layers\n",
    "model.add(Conv2D(128, kernel_size=(3,3), activation='relu' , input_shape=(48,48,1)))\n",
    "model.add(MaxPooling2D(pool_size=(2,2)))\n",
    "model.add(Dropout(0.4))\n",
    "\n",
    "model.add(Conv2D(256, kernel_size=(3,3), activation='relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2,2)))\n",
    "model.add(Dropout(0.4))\n",
    "\n",
    "model.add(Conv2D(512, kernel_size=(3,3), activation='relu' ))\n",
    "model.add(MaxPooling2D(pool_size=(2,2)))\n",
    "model.add(Dropout(0.4))\n",
    "\n",
    "model.add(Conv2D(512, kernel_size=(3,3), activation='relu' ))\n",
    "model.add(MaxPooling2D(pool_size=(2,2)))\n",
    "model.add(Dropout(0.4))\n",
    "\n",
    "model.add(Flatten())\n",
    "\n",
    "#fully connected layers\n",
    "model.add(Dense(512, activation='relu'))\n",
    "model.add(Dropout(0.4))\n",
    "model.add(Dense(256, activation='relu'))\n",
    "model.add(Dropout(0.3))\n",
    "\n",
    "#output layer\n",
    "model.add(Dense(7,activation='softmax'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "7f41ee4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer = 'adam', loss = 'categorical_crossentropy', metrics = 'accuracy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "3f926bf4",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "226/226 [==============================] - 447s 2s/step - loss: 1.8224 - accuracy: 0.2439 - val_loss: 1.8091 - val_accuracy: 0.2614\n",
      "Epoch 2/100\n",
      "226/226 [==============================] - 843s 4s/step - loss: 1.7996 - accuracy: 0.2517 - val_loss: 1.7706 - val_accuracy: 0.2621\n",
      "Epoch 3/100\n",
      "226/226 [==============================] - 436s 2s/step - loss: 1.7028 - accuracy: 0.3063 - val_loss: 1.6359 - val_accuracy: 0.3389\n",
      "Epoch 4/100\n",
      "226/226 [==============================] - 963s 4s/step - loss: 1.5745 - accuracy: 0.3808 - val_loss: 1.4441 - val_accuracy: 0.4584\n",
      "Epoch 5/100\n",
      "226/226 [==============================] - 439s 2s/step - loss: 1.4852 - accuracy: 0.4235 - val_loss: 1.3768 - val_accuracy: 0.4750\n",
      "Epoch 6/100\n",
      "226/226 [==============================] - 439s 2s/step - loss: 1.4256 - accuracy: 0.4513 - val_loss: 1.3041 - val_accuracy: 0.4986\n",
      "Epoch 7/100\n",
      "226/226 [==============================] - 439s 2s/step - loss: 1.3966 - accuracy: 0.4628 - val_loss: 1.2652 - val_accuracy: 0.5194\n",
      "Epoch 8/100\n",
      "226/226 [==============================] - 448s 2s/step - loss: 1.3510 - accuracy: 0.4851 - val_loss: 1.2562 - val_accuracy: 0.5232\n",
      "Epoch 9/100\n",
      "226/226 [==============================] - 459s 2s/step - loss: 1.3239 - accuracy: 0.4921 - val_loss: 1.2160 - val_accuracy: 0.5372\n",
      "Epoch 10/100\n",
      "226/226 [==============================] - 451s 2s/step - loss: 1.3044 - accuracy: 0.5005 - val_loss: 1.2060 - val_accuracy: 0.5491\n",
      "Epoch 11/100\n",
      "226/226 [==============================] - 450s 2s/step - loss: 1.2783 - accuracy: 0.5164 - val_loss: 1.1751 - val_accuracy: 0.5536\n",
      "Epoch 12/100\n",
      "226/226 [==============================] - 457s 2s/step - loss: 1.2668 - accuracy: 0.5171 - val_loss: 1.1705 - val_accuracy: 0.5613\n",
      "Epoch 13/100\n",
      "226/226 [==============================] - 444s 2s/step - loss: 1.2454 - accuracy: 0.5250 - val_loss: 1.1531 - val_accuracy: 0.5626\n",
      "Epoch 14/100\n",
      "226/226 [==============================] - 439s 2s/step - loss: 1.2376 - accuracy: 0.5289 - val_loss: 1.1405 - val_accuracy: 0.5665\n",
      "Epoch 15/100\n",
      "226/226 [==============================] - 443s 2s/step - loss: 1.2207 - accuracy: 0.5330 - val_loss: 1.1313 - val_accuracy: 0.5768\n",
      "Epoch 16/100\n",
      "226/226 [==============================] - 441s 2s/step - loss: 1.2057 - accuracy: 0.5417 - val_loss: 1.1262 - val_accuracy: 0.5778\n",
      "Epoch 17/100\n",
      "226/226 [==============================] - 448s 2s/step - loss: 1.1908 - accuracy: 0.5464 - val_loss: 1.1250 - val_accuracy: 0.5750\n",
      "Epoch 18/100\n",
      "226/226 [==============================] - 441s 2s/step - loss: 1.1889 - accuracy: 0.5455 - val_loss: 1.1176 - val_accuracy: 0.5780\n",
      "Epoch 19/100\n",
      "226/226 [==============================] - 444s 2s/step - loss: 1.1831 - accuracy: 0.5534 - val_loss: 1.1112 - val_accuracy: 0.5811\n",
      "Epoch 20/100\n",
      "226/226 [==============================] - 407s 2s/step - loss: 1.1697 - accuracy: 0.5561 - val_loss: 1.1070 - val_accuracy: 0.5812\n",
      "Epoch 21/100\n",
      "226/226 [==============================] - 384s 2s/step - loss: 1.1583 - accuracy: 0.5593 - val_loss: 1.0991 - val_accuracy: 0.5883\n",
      "Epoch 22/100\n",
      "226/226 [==============================] - 376s 2s/step - loss: 1.1466 - accuracy: 0.5630 - val_loss: 1.1026 - val_accuracy: 0.5863\n",
      "Epoch 23/100\n",
      "226/226 [==============================] - 371s 2s/step - loss: 1.1400 - accuracy: 0.5675 - val_loss: 1.0853 - val_accuracy: 0.5910\n",
      "Epoch 24/100\n",
      "226/226 [==============================] - 963s 4s/step - loss: 1.1300 - accuracy: 0.5732 - val_loss: 1.0874 - val_accuracy: 0.5911\n",
      "Epoch 25/100\n",
      "226/226 [==============================] - 394s 2s/step - loss: 1.1224 - accuracy: 0.5750 - val_loss: 1.0797 - val_accuracy: 0.5960\n",
      "Epoch 26/100\n",
      "226/226 [==============================] - 401s 2s/step - loss: 1.1171 - accuracy: 0.5758 - val_loss: 1.0747 - val_accuracy: 0.5931\n",
      "Epoch 27/100\n",
      "226/226 [==============================] - 423s 2s/step - loss: 1.1152 - accuracy: 0.5798 - val_loss: 1.0837 - val_accuracy: 0.5938\n",
      "Epoch 28/100\n",
      "226/226 [==============================] - 454s 2s/step - loss: 1.1081 - accuracy: 0.5818 - val_loss: 1.0768 - val_accuracy: 0.6001\n",
      "Epoch 29/100\n",
      "226/226 [==============================] - 409s 2s/step - loss: 1.0930 - accuracy: 0.5870 - val_loss: 1.0674 - val_accuracy: 0.6010\n",
      "Epoch 30/100\n",
      "226/226 [==============================] - 404s 2s/step - loss: 1.0870 - accuracy: 0.5887 - val_loss: 1.0570 - val_accuracy: 0.6090\n",
      "Epoch 31/100\n",
      "226/226 [==============================] - 426s 2s/step - loss: 1.0808 - accuracy: 0.5915 - val_loss: 1.0932 - val_accuracy: 0.5943\n",
      "Epoch 32/100\n",
      "226/226 [==============================] - 405s 2s/step - loss: 1.0769 - accuracy: 0.5918 - val_loss: 1.0604 - val_accuracy: 0.6043\n",
      "Epoch 33/100\n",
      "226/226 [==============================] - 410s 2s/step - loss: 1.0702 - accuracy: 0.5971 - val_loss: 1.0661 - val_accuracy: 0.6044\n",
      "Epoch 34/100\n",
      "226/226 [==============================] - 387s 2s/step - loss: 1.0619 - accuracy: 0.5999 - val_loss: 1.0505 - val_accuracy: 0.6087\n",
      "Epoch 35/100\n",
      "226/226 [==============================] - 366s 2s/step - loss: 1.0529 - accuracy: 0.6027 - val_loss: 1.0534 - val_accuracy: 0.6078\n",
      "Epoch 36/100\n",
      "226/226 [==============================] - 369s 2s/step - loss: 1.0488 - accuracy: 0.6044 - val_loss: 1.0560 - val_accuracy: 0.6081\n",
      "Epoch 37/100\n",
      "226/226 [==============================] - 377s 2s/step - loss: 1.0410 - accuracy: 0.6102 - val_loss: 1.0456 - val_accuracy: 0.6149\n",
      "Epoch 38/100\n",
      "226/226 [==============================] - 409s 2s/step - loss: 1.0371 - accuracy: 0.6098 - val_loss: 1.0425 - val_accuracy: 0.6146\n",
      "Epoch 39/100\n",
      "226/226 [==============================] - 404s 2s/step - loss: 1.0221 - accuracy: 0.6134 - val_loss: 1.0534 - val_accuracy: 0.6073\n",
      "Epoch 40/100\n",
      "226/226 [==============================] - 471s 2s/step - loss: 1.0304 - accuracy: 0.6115 - val_loss: 1.0455 - val_accuracy: 0.6104\n",
      "Epoch 41/100\n",
      "150/226 [==================>...........] - ETA: 2:25 - loss: 1.0191 - accuracy: 0.6150"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[19], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mx_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43my\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43my_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m128\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mepochs\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m100\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mvalidation_data\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43m(\u001b[49m\u001b[43mx_test\u001b[49m\u001b[43m,\u001b[49m\u001b[43my_test\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\Appdata\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\keras\\src\\utils\\traceback_utils.py:65\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     63\u001b[0m filtered_tb \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m     64\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m---> 65\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     66\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m     67\u001b[0m     filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n",
      "File \u001b[1;32m~\\Appdata\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\keras\\src\\engine\\training.py:1783\u001b[0m, in \u001b[0;36mModel.fit\u001b[1;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[0;32m   1775\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m tf\u001b[38;5;241m.\u001b[39mprofiler\u001b[38;5;241m.\u001b[39mexperimental\u001b[38;5;241m.\u001b[39mTrace(\n\u001b[0;32m   1776\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtrain\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m   1777\u001b[0m     epoch_num\u001b[38;5;241m=\u001b[39mepoch,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1780\u001b[0m     _r\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m,\n\u001b[0;32m   1781\u001b[0m ):\n\u001b[0;32m   1782\u001b[0m     callbacks\u001b[38;5;241m.\u001b[39mon_train_batch_begin(step)\n\u001b[1;32m-> 1783\u001b[0m     tmp_logs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain_function\u001b[49m\u001b[43m(\u001b[49m\u001b[43miterator\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1784\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m data_handler\u001b[38;5;241m.\u001b[39mshould_sync:\n\u001b[0;32m   1785\u001b[0m         context\u001b[38;5;241m.\u001b[39masync_wait()\n",
      "File \u001b[1;32m~\\Appdata\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\tensorflow\\python\\util\\traceback_utils.py:150\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    148\u001b[0m filtered_tb \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m    149\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 150\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    151\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m    152\u001b[0m   filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n",
      "File \u001b[1;32m~\\Appdata\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\tensorflow\\python\\eager\\polymorphic_function\\polymorphic_function.py:831\u001b[0m, in \u001b[0;36mFunction.__call__\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    828\u001b[0m compiler \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mxla\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jit_compile \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnonXla\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    830\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m OptionalXlaContext(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jit_compile):\n\u001b[1;32m--> 831\u001b[0m   result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    833\u001b[0m new_tracing_count \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mexperimental_get_tracing_count()\n\u001b[0;32m    834\u001b[0m without_tracing \u001b[38;5;241m=\u001b[39m (tracing_count \u001b[38;5;241m==\u001b[39m new_tracing_count)\n",
      "File \u001b[1;32m~\\Appdata\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\tensorflow\\python\\eager\\polymorphic_function\\polymorphic_function.py:867\u001b[0m, in \u001b[0;36mFunction._call\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    864\u001b[0m   \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lock\u001b[38;5;241m.\u001b[39mrelease()\n\u001b[0;32m    865\u001b[0m   \u001b[38;5;66;03m# In this case we have created variables on the first call, so we run the\u001b[39;00m\n\u001b[0;32m    866\u001b[0m   \u001b[38;5;66;03m# defunned version which is guaranteed to never create variables.\u001b[39;00m\n\u001b[1;32m--> 867\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mtracing_compilation\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcall_function\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    868\u001b[0m \u001b[43m      \u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwds\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_no_variable_creation_config\u001b[49m\n\u001b[0;32m    869\u001b[0m \u001b[43m  \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    870\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_variable_creation_config \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    871\u001b[0m   \u001b[38;5;66;03m# Release the lock early so that multiple threads can perform the call\u001b[39;00m\n\u001b[0;32m    872\u001b[0m   \u001b[38;5;66;03m# in parallel.\u001b[39;00m\n\u001b[0;32m    873\u001b[0m   \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lock\u001b[38;5;241m.\u001b[39mrelease()\n",
      "File \u001b[1;32m~\\Appdata\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\tensorflow\\python\\eager\\polymorphic_function\\tracing_compilation.py:139\u001b[0m, in \u001b[0;36mcall_function\u001b[1;34m(args, kwargs, tracing_options)\u001b[0m\n\u001b[0;32m    137\u001b[0m bound_args \u001b[38;5;241m=\u001b[39m function\u001b[38;5;241m.\u001b[39mfunction_type\u001b[38;5;241m.\u001b[39mbind(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m    138\u001b[0m flat_inputs \u001b[38;5;241m=\u001b[39m function\u001b[38;5;241m.\u001b[39mfunction_type\u001b[38;5;241m.\u001b[39munpack_inputs(bound_args)\n\u001b[1;32m--> 139\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunction\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_flat\u001b[49m\u001b[43m(\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# pylint: disable=protected-access\u001b[39;49;00m\n\u001b[0;32m    140\u001b[0m \u001b[43m    \u001b[49m\u001b[43mflat_inputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcaptured_inputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfunction\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcaptured_inputs\u001b[49m\n\u001b[0;32m    141\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\Appdata\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\tensorflow\\python\\eager\\polymorphic_function\\concrete_function.py:1264\u001b[0m, in \u001b[0;36mConcreteFunction._call_flat\u001b[1;34m(self, tensor_inputs, captured_inputs)\u001b[0m\n\u001b[0;32m   1260\u001b[0m possible_gradient_type \u001b[38;5;241m=\u001b[39m gradients_util\u001b[38;5;241m.\u001b[39mPossibleTapeGradientTypes(args)\n\u001b[0;32m   1261\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (possible_gradient_type \u001b[38;5;241m==\u001b[39m gradients_util\u001b[38;5;241m.\u001b[39mPOSSIBLE_GRADIENT_TYPES_NONE\n\u001b[0;32m   1262\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m executing_eagerly):\n\u001b[0;32m   1263\u001b[0m   \u001b[38;5;66;03m# No tape is watching; skip to running the function.\u001b[39;00m\n\u001b[1;32m-> 1264\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_inference_function\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mflat_call\u001b[49m\u001b[43m(\u001b[49m\u001b[43margs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1265\u001b[0m forward_backward \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_select_forward_and_backward_functions(\n\u001b[0;32m   1266\u001b[0m     args,\n\u001b[0;32m   1267\u001b[0m     possible_gradient_type,\n\u001b[0;32m   1268\u001b[0m     executing_eagerly)\n\u001b[0;32m   1269\u001b[0m forward_function, args_with_tangents \u001b[38;5;241m=\u001b[39m forward_backward\u001b[38;5;241m.\u001b[39mforward()\n",
      "File \u001b[1;32m~\\Appdata\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\tensorflow\\python\\eager\\polymorphic_function\\atomic_function.py:217\u001b[0m, in \u001b[0;36mAtomicFunction.flat_call\u001b[1;34m(self, args)\u001b[0m\n\u001b[0;32m    215\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mflat_call\u001b[39m(\u001b[38;5;28mself\u001b[39m, args: Sequence[core\u001b[38;5;241m.\u001b[39mTensor]) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Any:\n\u001b[0;32m    216\u001b[0m \u001b[38;5;250m  \u001b[39m\u001b[38;5;124;03m\"\"\"Calls with tensor inputs and returns the structured output.\"\"\"\u001b[39;00m\n\u001b[1;32m--> 217\u001b[0m   flat_outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    218\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfunction_type\u001b[38;5;241m.\u001b[39mpack_output(flat_outputs)\n",
      "File \u001b[1;32m~\\Appdata\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\tensorflow\\python\\eager\\polymorphic_function\\atomic_function.py:252\u001b[0m, in \u001b[0;36mAtomicFunction.__call__\u001b[1;34m(self, *args)\u001b[0m\n\u001b[0;32m    250\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m record\u001b[38;5;241m.\u001b[39mstop_recording():\n\u001b[0;32m    251\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_bound_context\u001b[38;5;241m.\u001b[39mexecuting_eagerly():\n\u001b[1;32m--> 252\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_bound_context\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcall_function\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    253\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mname\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    254\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mlist\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43margs\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    255\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mlen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfunction_type\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mflat_outputs\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    256\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    257\u001b[0m   \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    258\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m make_call_op_in_graph(\n\u001b[0;32m    259\u001b[0m         \u001b[38;5;28mself\u001b[39m,\n\u001b[0;32m    260\u001b[0m         \u001b[38;5;28mlist\u001b[39m(args),\n\u001b[0;32m    261\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_bound_context\u001b[38;5;241m.\u001b[39mfunction_call_options\u001b[38;5;241m.\u001b[39mas_attrs(),\n\u001b[0;32m    262\u001b[0m     )\n",
      "File \u001b[1;32m~\\Appdata\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\tensorflow\\python\\eager\\context.py:1479\u001b[0m, in \u001b[0;36mContext.call_function\u001b[1;34m(self, name, tensor_inputs, num_outputs)\u001b[0m\n\u001b[0;32m   1477\u001b[0m cancellation_context \u001b[38;5;241m=\u001b[39m cancellation\u001b[38;5;241m.\u001b[39mcontext()\n\u001b[0;32m   1478\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m cancellation_context \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m-> 1479\u001b[0m   outputs \u001b[38;5;241m=\u001b[39m \u001b[43mexecute\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mexecute\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   1480\u001b[0m \u001b[43m      \u001b[49m\u001b[43mname\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdecode\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mutf-8\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1481\u001b[0m \u001b[43m      \u001b[49m\u001b[43mnum_outputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mnum_outputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1482\u001b[0m \u001b[43m      \u001b[49m\u001b[43minputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtensor_inputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1483\u001b[0m \u001b[43m      \u001b[49m\u001b[43mattrs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mattrs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1484\u001b[0m \u001b[43m      \u001b[49m\u001b[43mctx\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1485\u001b[0m \u001b[43m  \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1486\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m   1487\u001b[0m   outputs \u001b[38;5;241m=\u001b[39m execute\u001b[38;5;241m.\u001b[39mexecute_with_cancellation(\n\u001b[0;32m   1488\u001b[0m       name\u001b[38;5;241m.\u001b[39mdecode(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mutf-8\u001b[39m\u001b[38;5;124m\"\u001b[39m),\n\u001b[0;32m   1489\u001b[0m       num_outputs\u001b[38;5;241m=\u001b[39mnum_outputs,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1493\u001b[0m       cancellation_manager\u001b[38;5;241m=\u001b[39mcancellation_context,\n\u001b[0;32m   1494\u001b[0m   )\n",
      "File \u001b[1;32m~\\Appdata\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\tensorflow\\python\\eager\\execute.py:60\u001b[0m, in \u001b[0;36mquick_execute\u001b[1;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[0;32m     53\u001b[0m   \u001b[38;5;66;03m# Convert any objects of type core_types.Tensor to Tensor.\u001b[39;00m\n\u001b[0;32m     54\u001b[0m   inputs \u001b[38;5;241m=\u001b[39m [\n\u001b[0;32m     55\u001b[0m       tensor_conversion_registry\u001b[38;5;241m.\u001b[39mconvert(t)\n\u001b[0;32m     56\u001b[0m       \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(t, core_types\u001b[38;5;241m.\u001b[39mTensor)\n\u001b[0;32m     57\u001b[0m       \u001b[38;5;28;01melse\u001b[39;00m t\n\u001b[0;32m     58\u001b[0m       \u001b[38;5;28;01mfor\u001b[39;00m t \u001b[38;5;129;01min\u001b[39;00m inputs\n\u001b[0;32m     59\u001b[0m   ]\n\u001b[1;32m---> 60\u001b[0m   tensors \u001b[38;5;241m=\u001b[39m \u001b[43mpywrap_tfe\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mTFE_Py_Execute\u001b[49m\u001b[43m(\u001b[49m\u001b[43mctx\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_handle\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdevice_name\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mop_name\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     61\u001b[0m \u001b[43m                                      \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mattrs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnum_outputs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     62\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m core\u001b[38;5;241m.\u001b[39m_NotOkStatusException \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m     63\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m name \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "model.fit(x=x_train,y=y_train, batch_size = 128, epochs = 100, validation_data = (x_test,y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "f08fa1bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_json = model.to_json()\n",
    "with open(\"emotiondetector.json\", \"w\") as json_file:\n",
    "    json_file.write(model_json)\n",
    "model.save(\"emotiondetector.keras\")    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "7f151333",
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import model_from_json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "cb17819e",
   "metadata": {},
   "outputs": [],
   "source": [
    "json_file = open(\"emotiondetector.json\", \"r\")\n",
    "model_json = json_file.read()\n",
    "json_file.close()\n",
    "model = model_from_json(model_json)\n",
    "model.load_weights(\"emotiondetector.keras\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "5fc3e439",
   "metadata": {},
   "outputs": [],
   "source": [
    "label = ['angry','disgust','fear','happy','neutral','sad','surprise']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "f2cab596",
   "metadata": {},
   "outputs": [],
   "source": [
    "def ef(image):\n",
    "    img = load_img(image,\"grayscale\" = True )\n",
    "    feature = np.array(img)\n",
    "    feature = feature.reshape(1,48,48,1)\n",
    "    return feature/255.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "bcd3127c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "original image is of sad\n",
      "1/1 [==============================] - 0s 47ms/step\n",
      "model prediction is  sad\n"
     ]
    }
   ],
   "source": [
    "images = 'images/train/sad/89.jpg'\n",
    "print(\"original image is of sad\")\n",
    "img = ef(images)\n",
    "pred = model.predict(img)\n",
    "pred_label = label[pred.argmax()]\n",
    "print (\"model prediction is \", pred_label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "1bad7501",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "e3673064",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "original image is of angry\n",
      "1/1 [==============================] - 0s 52ms/step\n",
      "model prediction is  angry\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Shruti\\Appdata\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\keras\\src\\utils\\image_utils.py:409: UserWarning: grayscale is deprecated. Please use color_mode = \"grayscale\"\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x242fb211f10>"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "image = 'images/train/angry/22.jpg'\n",
    "print(\"original image is of angry\")\n",
    "img = ef(image)\n",
    "pred = model.predict(img)\n",
    "pred_label = label[pred.argmax()]\n",
    "print (\"model prediction is \", pred_label)\n",
    "plt.imshow(img.reshape(48,48),cmap='gray')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "641c6d68",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e95fa15",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
